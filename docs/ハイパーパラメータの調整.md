# 教師なし学習

## パラメータとハイパーバラメータ
* パラメータ
	- モデルの学習実行後に獲得される値(wやσなど)
* ハイパーパラメータ
	- 各アルゴリズムに付随して、アルゴリズムの挙動を制御するための値
	- モデルの学習実行前に調整することでモデルの性能向上や過学習の抑制、効率の良い学習などが期待できる

## K-分割交差検証 (K-fold cross-validation)
ホールドアウト法では、与えられたデータセットを学習用データセット・テスト用データセットを 2 分割したが、
実際の開発時にはモデルの性能評価をより適切にするためにデータを 3 分割してモデルを評価することが一般的。

|データ名称|使用目的|
|:--|:--|
|学習用データセット (train)	|モデルを学習させるためのデータセット|
|検証用データセット (validation)|ハイパーパラメータの調整が適切なのか検証するためのデータセット|
|テスト用データセット (test)|学習済みモデルの性能を評価するためのデータセット|
* 学習用データセットと検証用データセットは学習段階で用いられ、テスト用データセットは最終的なモデルの予測精度の確認のためにのみ使用する

しかし、十分なデータ量が用意できない場合には 3 分割すると偏りが生じて適切な学習・検証が行われない可能性があり、
そのようなデータの偏りを回避する方法として `K-分割交差検証 (K-fold cross-validation)`が用いられる。

<3 Step>
1. データセットを `K` 個に分割
2. 分割したデータの 1 個を検証用データセットとし、残り `K-1` 個を学習用データセットとして学習を実行
	*  1 回で学習を終わらせず、計 K 回の学習を実施する
	* 既に検証用データセットに使ったデータを次は学習用データセットとして使用し、新たに検証用データセットを選択する
3. 各検証の結果を平均して最終的な検証結果とする

## ハイパーパラメータの調整方法
以下の方法を使って、ハイパーパラメータを調整する。

1. 手動での調整
2. グリッドサーチ (Grid Search)
3. ランダムサーチ (Random Search)
4. ベイズ最適化 (Bayesian Optimization

### 事前準備
```
import numpy as np
import pandas as pd
from sklearn.datasets import load_breast_cancer

# 乳がんに関するデータセット
# 目標値が陰性か陽性かの 2 つの値である二値分類の問題設定
dataset = load_breast_cancer()

t = dataset.target
x = dataset.data

print(x.shape, t.shape)
```

```
(569, 30) (569,)
```

### 手動での調整

```
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

# 学習用データセット・検証用データセット・テスト用データセットの 3 つに分割

# 与えられたデータを「テスト用データセット：その他 ＝ 20 ： 80 」に分割
x_train_val, x_test, t_train_val, t_test = train_test_split(x, t, test_size=0.2, random_state=1)

# 「その他」のデータを「検証用データセット：学習用データセット ＝ 30 ： 70 」に分割
# 検証用データセット：学習用データセット＝ 30 ： 70
x_train, x_val, t_train, t_val = train_test_split(x_train_val, t_train_val, test_size=0.3, random_state=1)

print(x_train.shape, x_val.shape, x_test.shape)

# 決定木で学習
dtree = DecisionTreeClassifier(random_state=0).fit(x_train, t_train)

# ハイパーパラメータを設定して、モデルの定義
dtree2 = DecisionTreeClassifier(max_depth=10, min_samples_split=30, random_state=0).fit(x_train, t_train)

# スコア確認
print('train score(前) : ', dtree.score(x_train, t_train))
print('train score(後) : ', dtree2.score(x_train, t_train))
print('validation score(前) : ', dtree.score(x_val, t_val))
print('validation score(後) : ', dtree2.score(x_val, t_val))
print('test score(前) :', dtree.score(x_test, t_test))
print('test score(後) :', dtree2.score(x_test, t_test))
```

```
(318, 30) (137, 30) (114, 30)
train score(前) :  1.0
train score(後) :  0.9308176100628931
validation score(前) :  0.927007299270073
validation score(後) :  0.9562043795620438
test score(前) : 0.9210526315789473
test score(後) : 0.9298245614035088
```

### グリッドサーチ (Grid Search)
最適なハイパーパラメータを獲得するにはある程度の探索（試行錯誤）を行う必要がある。

グリッドサーチは、`効率的に最適なハイパーパラメータを探索する方法`の一つ。

決定木のハイパーパラメータを例に説明する。

1. ハイパーパラメータを探索する範囲を決める
	- `max_depth` と `min_samples_split` の値を調整したい場合、`5、10、15、20、25` のように範囲をそれぞれ決める
	- パイパーパラメータは、5 * 5 = 25の組み合わせになる
2. 全てのパイパーパラメータの組み合わせを使用して、学習・検証を行う
3. 結果から予測精度が最も高いハイパーパラメータを採用する

* メリット：指定した範囲を網羅するため、ある程度漏れがなくハイパーパラメータの探索を行うことができる
* デメリット：場合によっては、数十～数百パターンの組合せを計算するため学習に時間を要する

```
# GridSearchCV クラスのインポート
from sklearn.model_selection import GridSearchCV

# GridSearchCV クラスの使用には下記の 3 つを準備する必要がある
# estimator ：学習に使用するモデル
estimator = DecisionTreeClassifier(random_state=0)
# param_grid ：ハイパーパラメータを探索する範囲
param_grid = [{
    'max_depth': [3, 20, 50],
    'min_samples_split': [3, 20, 30]
}]
# cv ：K-分割交差検証の K の値
cv = 5

# K-分割交差検証を使いたいため、学習用データセットと検証用データセットに分割する前の
# データセットである x_train_val と t_train_val を使用
# return_train_score=False を設定することで学習に対する予測精度の検証が行われない
# False にすると計算コストを抑えることができる
tuned_model = GridSearchCV(estimator=estimator,
                           param_grid=param_grid,
                           cv=cv, return_train_score=False
						   ).fit(x_train_val, t_train_val)

# 検証結果の確認
# ハイパーパラメータの種類が 2 つで、各 3 個ずつ値を指定したので 3 × 3 = 9 パターンの計算が行われる
# K を 5 としたので 5 種類の結果 (split0_test_score ~ split4_test_score) が出力
print(pd.DataFrame(tuned_model.cv_results_).T)
```

```
mean_fit_time                                              0.007147
std_fit_time                                               0.000441
mean_score_time                                            0.000821
std_score_time                                             0.000045
param_max_depth                                                  50
param_min_samples_split                                          30
params                   {'max_depth': 50, 'min_samples_split': 30}
split0_test_score                                          0.912088
split1_test_score                                          0.901099
split2_test_score                                          0.934066
split3_test_score                                          0.945055
split4_test_score                                          0.901099
mean_test_score                                            0.918681
std_test_score                                             0.017855
rank_test_score                                                   6
...
```

`mean_test_score`の値からそのモデルの予測精度の確認ができる。
基本的にはこの値を確認し、どのハイパーパラメータが効果が強いのかを確認する。

基本的にパラメータの変更を繰り返して、最適な値を探る。

```
estimator = DecisionTreeClassifier(random_state=0)
cv = 5
param_grid = [{
    'max_depth': [5, 10, 15] ,
    'min_samples_split': [10, 12, 15]
}]
# モデルの定義
tuned_model = GridSearchCV(estimator=estimator,
                           param_grid=param_grid,
                           cv=cv, return_train_score=False)

# モデルの学習
tuned_model.fit(x_train_val, t_train_val)
# 学習結果の確認
pd.DataFrame(tuned_model.cv_results_).T
```

最初はある程度大きな幅を持ってグリッドサーチを行い、徐々に範囲を狭めてより予測精度の高いハイパーパラメータを探していく。

```
# 最も予測精度の高かったハイパーパラメータの確認
tuned_model.best_params_
```

```
{'max_depth': 20, 'min_samples_split': 3}
```

best_estimator_ で最も検証用データセットに対しての予測精度が最も高かったハイパーパラメータで
学習したモデルを取得することが可能。

```
# 最も予測精度の高かったモデルの引き継ぎ
best_model = tuned_model.best_estimator_

# モデルの検証
print(best_model.score(x_train_val, t_train_val))
print(best_model.score(x_test, t_test))
```

```
1.0
0.9385964912280702
```

### ランダムサーチ (Random Search)
グリッドサーチは、グリッド上にしか探索できないという点がある。

一方、ランダムサーチは`指定した範囲のハイパーパラメータをランダムに抽出し、学習・検証を行うことができる`。

* メリット --- 広い範囲を探索することがより効率的に行える
* デメリット --- 全てのハイパーパラメータを探索するわけではないため、そのハイパーパラメータが最適かは判断が難しい

ランダムサーチである程度の範囲を絞ったあとに、グリッドサーチで局所的に探索するという方法も考えられる。

```
# RandomizedSearchCV クラスのインポート
from sklearn.model_selection import RandomizedSearchCV

# 学習に使用するアルゴリズム
estimator = DecisionTreeClassifier(random_state=0)

# ハイパーパラメータを探索する範囲の指定
param_distributions = {
    'max_depth': list(range(5, 100, 2)),
    'min_samples_split': list(range(2, 50, 1))
}

# 試行回数の指定
# 指定した範囲のハイパーパラメータをランダムに抽出し学習を行うため、何回学習を試行するかの回数を指定する必要がある
n_iter = 100
#  K- 分割交差検証
cv = 5

# モデルの定義
# ランダムにハイパーパラメータが抽出されるため、再現性の確保のために乱数のシードの固定を行う
tuned_model = RandomizedSearchCV(
    estimator=estimator,
    param_distributions=param_distributions,
    n_iter=n_iter, cv=cv,
    random_state=0, return_train_score=False
)

# モデルの学習＆検証
tuned_model.fit(x_train_val, t_train_val)

# 学習結果の確認（スコアの高い順に表示）
pd.DataFrame(tuned_model.cv_results_).sort_values('rank_test_score').T

# 最も予測精度の高かったハイパーパラメータの確認
tuned_model.best_params_

# 最も予測精度の高かったモデルの引き継ぎ
best_model = tuned_model.best_estimator_

# モデルの検証
print(best_model.score(x_train_val, t_train_val))
print(best_model.score(x_test, t_test))
```

### ベイズ最適化 (Bayesian Optimization)
ベイズ最適化では、事前分布と事後分布と呼ばれる確率統計の理論を使用してハイパーパラメータの探索を行う。

その際に、`探索`と`活用`と呼ばれる試行錯誤を繰り返す。

* 探索：まだ試していない値の範囲でハイパーパラメータを更新して、予測精度がどう変化するか情報を得る
* 活用：探索で得られた情報をもとに、予測精度が高まる可能性が高い範囲にハイパーパラメータを更新する

ランダムサーチでは、ランダムにハイパーパラメータの値を抽出し学習行なったが、
ペイズ最適化では探索や活用で得られた情報を元にハイパーパラメータを調整していくため、
より効率的に予測精度が高くなるハイパーパラメータを見つけることができると言われている。

ベイズ最適化を実装するため、[Optuna](https://optuna.org/) というフレームワークを使用する。

Optuna では最初に関数 objective を定義して内部に以下の要素を関数として順に定義する。

1. ハイパーパラメータごとに探索範囲を指定
2. 学習に使用するアルゴリズムを指定
3. 学習の実行、検証結果の表示

```
import optuna
from sklearn.model_selection import cross_val_score

def objective(trial, x, t, cv):
    # 1. ハイパーパラメータごとに探索範囲を指定
    max_depth = trial.suggest_int('max_depth', 2, 100)
    min_samples_split = trial.suggest_int('min_samples_split', 2, 100)

    # 2. 学習に使用するアルゴリズムを指定
    estimator = DecisionTreeClassifier(
      max_depth = max_depth,
      min_samples_split = min_samples_split
    )

    # 3. 学習の実行、検証結果の表示
    # ハイパーパラメータの調整を行う
    # returnで取得した検証結果を最小化(最大化)するように調整する
    print('Current_params : ', trial.params)
    # cross_val_scoreで K-分割交差検証を使用する
    accuracy = cross_val_score(estimator, x, t, cv=cv).mean()
    return accuracy

# study オブジェクトの作成（最大化）
# デフォルトでは最小化を行う
# 最大化を目的とする場合には、direction='maximize' を指定
study = optuna.create_study(sampler=optuna.samplers.RandomSampler(0), direction='maximize')

# K 分割交差検証の K
cv = 5
# 目的関数の最適化
# lambda 関数を使用して objective 関数に追加の引数を渡す点と n_trials で試行回数を指定するを覚えておく
study.optimize(lambda trial: objective(trial, x_train_val, t_train_val, cv), n_trials=10)

print(study.best_trial)
```


```
[I 2022-10-26 11:58:27,336] Trial 0 finished with value: 0.9208791208791209 and parameters: {'max_depth': 56, 'min_samples_split': 72}. Best is trial 0 with value: 0.9208791208791209.
[I 2022-10-26 11:58:27,391] Trial 1 finished with value: 0.9208791208791209 and parameters: {'max_depth': 61, 'min_samples_split': 55}. Best is trial 0 with value: 0.9208791208791209.
[I 2022-10-26 11:58:27,443] Trial 2 finished with value: 0.9208791208791209 and parameters: {'max_depth': 43, 'min_samples_split': 65}. Best is trial 0 with value: 0.9208791208791209.
Current_params :  {'max_depth': 56, 'min_samples_split': 72}
Current_params :  {'max_depth': 61, 'min_samples_split': 55}
Current_params :  {'max_depth': 43, 'min_samples_split': 65}
Current_params :  {'max_depth': 45, 'min_samples_split': 90}
[I 2022-10-26 11:58:27,500] Trial 3 finished with value: 0.9208791208791209 and parameters: {'max_depth': 45, 'min_samples_split': 90}. Best is trial 0 with value: 0.9208791208791209.
[I 2022-10-26 11:58:27,562] Trial 4 finished with value: 0.9186813186813187 and parameters: {'max_depth': 97, 'min_samples_split': 39}. Best is trial 0 with value: 0.9208791208791209.
[I 2022-10-26 11:58:27,615] Trial 5 finished with value: 0.9186813186813187 and parameters: {'max_depth': 80, 'min_samples_split': 54}. Best is trial 0 with value: 0.9208791208791209.
[I 2022-10-26 11:58:27,677] Trial 6 finished with value: 0.9208791208791209 and parameters: {'max_depth': 58, 'min_samples_split': 93}. Best is trial 0 with value: 0.9208791208791209.
Current_params :  {'max_depth': 97, 'min_samples_split': 39}
Current_params :  {'max_depth': 80, 'min_samples_split': 54}
Current_params :  {'max_depth': 58, 'min_samples_split': 93}
Current_params :  {'max_depth': 9, 'min_samples_split': 10}
[I 2022-10-26 11:58:27,736] Trial 7 finished with value: 0.9406593406593406 and parameters: {'max_depth': 9, 'min_samples_split': 10}. Best is trial 7 with value: 0.9406593406593406.
[I 2022-10-26 11:58:27,788] Trial 8 finished with value: 0.9208791208791209 and parameters: {'max_depth': 4, 'min_samples_split': 84}. Best is trial 7 with value: 0.9406593406593406.
Current_params :  {'max_depth': 4, 'min_samples_split': 84}
Current_params :  {'max_depth': 79, 'min_samples_split': 88}
[I 2022-10-26 11:58:27,963] Trial 9 finished with value: 0.9186813186813187 and parameters: {'max_depth': 79, 'min_samples_split': 88}. Best is trial 7 with value: 0.9406593406593406.
FrozenTrial(number=7, values=[0.9406593406593406], datetime_start=datetime.datetime(2022, 10, 26, 11, 58, 27, 686554), datetime_complete=datetime.datetime(2022, 10, 26, 11, 58, 27, 736274), params={'max_depth': 9, 'min_samples_split': 10}, distributions={'max_depth': IntDistribution(high=100, log=False, low=2, step=1), 'min_samples_split': IntDistribution(high=100, log=False, low=2, step=1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=7, state=TrialState.COMPLETE, value=None)
```

print で出力している値はハイパーパラメータの値になる。

学習が完了するたびに、現在の正解率を表す resulted in value と現在までの最も良かった正解率を表示している。

学習が終了したので、最も予測精度の高かったハイパーパラメータを確認するために study.best_params を実行する。

```
# 最も予測精度の高かったハイパーパラメータの確認
study.best_params
```
```
{'max_depth': 9, 'min_samples_split': 10}
```

Optuna でのハイパーパラメータ調整は先ほどと異なり、最も予測精度の高かったハイパーパラメータのみが取得でき、
学習済みモデルは取得することができないため、再度学習を行う必要がある。

```
# 最適なハイパーパラメータを設定したモデルの定義
#  ** のようにアスタリスクを 2 つ付け、先程のハイパーパラメータをモデルのインスタンス化を行う際に引数に渡すことで、
# ハイパーパラメータを設定することが可能
best_model = DecisionTreeClassifier(**study.best_params)

# モデルの学習
best_model.fit(x_train_val, t_train_val)

# モデルの検証
print(best_model.score(x_train_val, t_train_val))
print(best_model.score(x_test, t_test))
```
